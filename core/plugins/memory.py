import hashlib
import threading
import json
import os
from collections import deque
import uuid

from numpy.linalg import norm
import asyncio
from concurrent.futures import ThreadPoolExecutor
import numpy as np
from datetime import datetime
import logging
from core.utils.intent import IntentRecognizer,IntentResult
from core.plugins.base import PluginBase,PluginResult,PluginEvent,ChatHistory
logger = logging.getLogger(__name__)
# Cosine similarity function
cos_sim = lambda a, b: (a @ b.T) / (norm(a) * norm(b))


class MemoryManager:
    _instance = None
    _lock = threading.Lock()

    def __new__(cls, *args, **kwargs):
        with cls._lock:
            if cls._instance is None:
                cls._instance = super(MemoryManager, cls).__new__(cls)  
        return cls._instance

    def __init__(
            self,
            llm,
            embd,
            summary_prompt: str = "è¯·æ€»ç»“ä¸‹é¢çš„èŠå¤©å†…å®¹,å¿…é¡»åœ¨{content_len}å­—æ•°ä»¥å†…ï¼Œå¿…é¡»åŒ…å«èŠå¤©çš„å®Œæ•´ç»†èŠ‚:\n\n{content}",
            max_memory_length: int = 1000,
            summary_length: int = 1000,
            max_summary_length: int = 2000,

            memory_dir='memory_data'
        ):
        """
        åˆå§‹åŒ–è®°å¿†ç®¡ç†ç±»
        :param embedding_model: ç”¨äºç”Ÿæˆæ–‡æœ¬åµŒå…¥çš„æ¨¡å‹
        :param max_memory_length: æœ€å¤§è®°å¿†æ€»å­—ç¬¦é•¿åº¦
        :param summary_length: æ¯æ¬¡ç”Ÿæˆçš„æ€»ç»“çš„é•¿åº¦
        :param memory_file: ä¿å­˜è®°å¿†æ•°æ®çš„æ–‡ä»¶è·¯å¾„
        """
        # print(f"åˆå§‹åŒ–è®°å¿†ç®¡ç†å™¨ max_memory_length:{max_memory_length} summary_length:{summary_length} max_summary_length:{max_summary_length}")
        self.max_memory_length = max_memory_length
        self.summary_length = summary_length
        self.max_summary_length = max_summary_length

        self.memory_data = {}  # ç”¨å­—å…¸ç®¡ç†æ¯ä¸ªç”¨æˆ·çš„è®°å¿†
        self.lock = threading.Lock()  # é”å¯¹è±¡ï¼Œç”¨äºçº¿ç¨‹åŒæ­¥
        self.summary_prompt = summary_prompt
        self.llm = llm
        self.embedding_model = embd  # ç”¨äºç”Ÿæˆæ–‡æœ¬çš„åµŒå…¥

        self.memory_dir = memory_dir
        if not os.path.exists(self.memory_dir):
            os.makedirs(self.memory_dir,exist_ok=True)  # åˆ›å»ºç›®å½•
        
        # ç¡®ä¿ç›®å½•å…·æœ‰è¯»å†™æƒé™
        if not os.access(self.memory_dir, os.W_OK):
            try:
                os.chmod(self.memory_dir, 0o700)  # è®¾ç½®è¯»å†™æƒé™
                logger.info(f"å·²ä¸ºç›®å½• {self.memory_dir} è®¾ç½®è¯»å†™æƒé™")
            except Exception as e:
                logger.warning(f"æ— æ³•ä¿®æ”¹ {self.memory_dir} çš„æƒé™: {e}")
                raise PermissionError(f"æ²¡æœ‰è¶³å¤Ÿæƒé™è®¿é—®ç›®å½•: {self.memory_dir}")
        # åŠ è½½å·²æœ‰è®°å¿†æˆ–åˆå§‹åŒ–æ–°çš„è®°å¿†
        self.load_memory()
        
        # ThreadPoolExecutor for async tasks
        self.executor = ThreadPoolExecutor()


        self.intent_recognizer = IntentRecognizer(self.embedding_model)
        self.intent_recognizer.register_intent(
            ["å›å¿†å¯¹è¯", "å›å¿†ä¸Šæ¬¡è®²çš„", "è¯·å›å¿†","æœ‰ä»€ä¹ˆè®°å¿†","åˆšæ‰è®²äº†ä»€ä¹ˆ","ä¸Šæ¬¡è®²äº†ä»€ä¹ˆ"], 
            self._recall_last_conversation, 
            similarity_threshold=0.7
        )
        self.intent_recognizer.register_intent(
            ["åˆ é™¤æˆ‘çš„è®°å¿†","åˆ é™¤æ‰€æœ‰è®°å¿†"], 
            self._del_all, 
            similarity_threshold=0.9
        )       
    
    def _recall_last_conversation(self,query: str, token_name: str)->str:
        """
        å›å¿†ä¸Šæ¬¡çš„å¯¹è¯
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        :param query: ç”¨æˆ·æŸ¥è¯¢
        :return: ä¸Šæ¬¡çš„å¯¹è¯å†…å®¹
        """
        user_memory = self.search_memory(token_name, query, top_k=5)
        

        if len(user_memory) == 0:
            
            user_memory = self.memory_data.get(token_name, {'memory':[]})
            
            user_memory = list(user_memory['memory'])
            user_memory = user_memory[-10:]        

            

        output = "\n".join([msg['content'] for msg in user_memory])

        
        return f"{query}\n\næˆ‘ä»¬ä¸Šæ¬¡èŠåˆ°äº†:\n\n{output}"

    def _generate_summary(self, chat_paragraph: list):
        """
        ç”ŸæˆèŠå¤©å†…å®¹çš„æ€»ç»“ï¼ˆå¯ä»¥æ ¹æ®å…·ä½“è¦æ±‚å®šåˆ¶æ€»ç»“é€»è¾‘ï¼‰
        :param chat_content: èŠå¤©å†…å®¹
        :return: æ€»ç»“çš„å­—ç¬¦ä¸²
        """
        if self.llm is None:
            return "".join([msg['content'] for msg in chat_paragraph])[:self.summary_length]
        
        response_message = []
        try:            
            llm_responses = self.llm.response(
                str(uuid.uuid4()), 
                [
                    {
                        "role": "user", 
                        "content": self.summary_prompt.format(content=json.dumps(chat_paragraph),content_len=self.summary_length)
                    }
                ]
            )
        except Exception as e:
            logger.warning(f"LLM å¤„ç†å‡ºé”™ {query}: {e}")
            return None

        for content in llm_responses:
            response_message.append(content)
        return "".join(response_message)

    def _forget_old_memory(self, token_name: str):
        """
        è¶…è¿‡æœ€å¤§è®°å¿†æ€»é•¿åº¦æ—¶ï¼Œåˆ é™¤ä¸é‡è¦çš„è®°å¿†
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        """
        user_memory = self.memory_data.get(token_name, {'memory': deque(), 'total_length': 0})

        while user_memory['total_length'] > self.max_memory_length and user_memory['memory']:
            # åˆ é™¤æœ€æ—§çš„èŠå¤©å†…å®¹å’Œå¯¹åº”çš„åµŒå…¥
            oldest_message = user_memory['memory'].popleft()
            oldest_embedding = user_memory['embeddings'].popleft()  # Remove corresponding embedding
            user_memory['total_length'] -= len(oldest_message['content'])



    def _update_summary(self, token_name: str, chat_paragraph: list[dict]):
        """
        æ›´æ–°è®°å¿†æ€»ç»“ï¼Œåˆå¹¶æ¯ä¸ªèŠå¤©æ®µè½çš„å†…å®¹å¹¶ç”Ÿæˆæ‘˜è¦
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        """      
        
        if len(chat_paragraph) == 0:
            return 
        
        summary = self._generate_summary(chat_paragraph)

        if summary is None or len(summary.strip()) == 0:
            return
        
        self.memory_data[token_name].setdefault('memory_summary', []).append(summary)

        # ç”Ÿæˆå¹¶ä¿å­˜æ‘˜è¦çš„åµŒå…¥
        summary_embedding = self.embedding_model.encode([summary])[0]
        self.memory_data[token_name].setdefault('summary_embeddings', []).append(summary_embedding)

    def _combine_summary(self, token_name: str):
        """
        å°†æ‰€æœ‰çš„è®°å¿†æ€»ç»“åˆå¹¶ä¸ºä¸€ä¸ª
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        """
        
        user_memory = self.memory_data.get(token_name, {'memory_summary': []})

        # å¦‚æœæ²¡æœ‰è¶…è¿‡æœ€å¤§æ€»ç»“é•¿åº¦ï¼Œç›´æ¥è¿”å›
        old_summary = "".join(user_memory['memory_summary'])
        if len(user_memory) == 0 or len(old_summary) < self.max_memory_length:
            logger.debug("ä¸éœ€è¦åˆå¹¶,æ€»ç»“é•¿åº¦ï¼š", len(old_summary))
            return
        logger.debug("åˆå¹¶å‰çš„æ€»ç»“é•¿åº¦ï¼š", len(old_summary))
        summary = self._generate_summary(user_memory['memory_summary'])
        logger.debug("åˆå¹¶åçš„æ€»ç»“é•¿åº¦ï¼š", len(summary))
        self.memory_data[token_name]['memory_summary'] = [summary]

        # ç”Ÿæˆå¹¶ä¿å­˜æ‘˜è¦çš„åµŒå…¥
        summary_embedding = self.embedding_model.encode([summary])[0]
        self.memory_data[token_name]['summary_embeddings'] = [summary_embedding]

    def _del_all(self, query:str, token_name: str)->str:
        """
        åˆ é™¤æ‰€æœ‰è®°å¿†
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        """
        self.memory_data[token_name] = {'memory': deque(), 'total_length': 0, 'memory_summary': [], 'summary_embeddings': [], 'embeddings': deque()}
        self.save_memory()
        return f"ä½ å¿…é¡»{query}\n\nä½ å¿…é¡»å›ç­”åŒæ„åˆ é™¤æ‰€æœ‰è®°å¿†"

    async def add_chat_paragraph(self, token_name: str, chat_paragraph: list[dict]):
        """
        æ·»åŠ ä¸€æ®µèŠå¤©å†…å®¹åˆ°è®°å¿†ä¸­
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        :param chat_paragraph: èŠå¤©æ®µè½ï¼ŒåŒ…å«å¤šæ¡èŠå¤©è®°å½•
        """
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(self.executor, self._add_chat_paragraph, token_name, chat_paragraph)

    def _add_chat_paragraph(self, token_name: str, chat_paragraph: list[dict]):
        with self.lock:  # ä½¿ç”¨é”ä¿è¯çº¿ç¨‹å®‰å…¨
            if token_name not in self.memory_data:
                self.memory_data[token_name] = {'memory': deque(), 'total_length': 0, 'memory_summary': [], 'summary_embeddings': [], 'embeddings': deque()}

            user_memory = self.memory_data[token_name]
            new_embeddings = []

            for message in chat_paragraph:
                role = message['role']
                content = message['content']

                chat_hash = hashlib.md5(content.encode()).hexdigest()

                user_memory['memory'].append({"role": role, "content": content, "hash": chat_hash, "datatime": "{:%Y-%m-%d %H:%M:%S}".format(datetime.now())})
                user_memory['total_length'] += len(content)

                # ç”ŸæˆåµŒå…¥
                embedding = self.embedding_model.encode([content])[0]  # ä½¿ç”¨åµŒå…¥æ¨¡å‹ç”ŸæˆåµŒå…¥
                user_memory['embeddings'].append(embedding)

            # æ›´æ–°è®°å¿†æ€»ç»“
            self._update_summary(token_name, chat_paragraph)

            # å¦‚æœè®°å¿†è¶…å‡ºäº†é™åˆ¶ï¼Œåˆ é™¤ä¸é‡è¦çš„å†…å®¹
            self._forget_old_memory(token_name)

            # åˆå¹¶å‹ç¼©è®°å¿†æ€»ç»“
            self._combine_summary(token_name)

            # ä¿å­˜è®°å¿†åˆ°æ–‡ä»¶
            self.save_memory()

    def handle_user_scene(self,token_name:str, query: str) -> str:
        """
        è§£æç”¨æˆ·æŸ¥è¯¢
        :param query: ç”¨æˆ·æŸ¥è¯¢
        :return: è§£æåçš„æŸ¥è¯¢
        """
        query = query.strip()
        if len(query) == 0:
            return query
        
        result:IntentResult = self.intent_recognizer.handle_query(query, token_name)
        if result.success:
            return result.response

        return query
    

    def get_memory_summary(self, token_name: str) -> str:
        """
        è·å–å½“å‰ç”¨æˆ·çš„è®°å¿†æ€»ç»“
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        :return: å½“å‰çš„æ€»ç»“
        """
        user_memory = self.memory_data.get(token_name, {'memory_summary': []})
        return "\n\n".join(user_memory['memory_summary'])

    def get_full_memory(self, token_name: str) -> list[str]:
        """
        è·å–å½“å‰ç”¨æˆ·çš„å®Œæ•´è®°å¿†å†…å®¹
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        :return: å½“å‰çš„æ‰€æœ‰è®°å¿†å†…å®¹
        """
        user_memory = self.memory_data.get(token_name, {'memory': []})
        return [msg['content'] for msg in user_memory['memory']]

    def search_memory(self, token_name: str, query: str, top_k: int = 5, threshold: float = 0.5):
        """
        ä½¿ç”¨åµŒå…¥è¿›è¡Œè®°å¿†æŸ¥è¯¢
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        :param query: æŸ¥è¯¢å†…å®¹
        :param top_k: è¿”å›æœ€ç›¸ä¼¼çš„è®°å¿†æ¡æ•°
        :param threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œä½äºæ­¤é˜ˆå€¼çš„ç»“æœå°†è¢«å¿½ç•¥
        :return: æœ€ç›¸ä¼¼çš„è®°å¿†æ¡ç›®
        """
        user_memory = self.memory_data.get(token_name, {'embeddings': []})
        if not user_memory['embeddings']:
            return []

        # ç”ŸæˆæŸ¥è¯¢çš„åµŒå…¥
        query_embedding = self.embedding_model.encode([query])[0]

        # è®¡ç®—æŸ¥è¯¢ä¸è®°å¿†ä¸­æ¯æ¡æ¶ˆæ¯çš„ç›¸ä¼¼åº¦
        similarities = [cos_sim(query_embedding, embedding) for embedding in user_memory['embeddings']]

        # è·å–æœ€ç›¸ä¼¼çš„è®°å¿†æ¡ç›®ï¼Œè¿‡æ»¤ç›¸ä¼¼åº¦ä½äºé˜ˆå€¼çš„ç»“æœ
        filtered_indices = [i for i, sim in enumerate(similarities) if sim >= threshold]
        top_indices = sorted(filtered_indices, key=lambda i: similarities[i], reverse=True)[:top_k]
        similar_memory = [user_memory['memory'][i] for i in top_indices]

        return similar_memory

    def search_memory_summary(self, token_name: str, query: str, top_k: int = 5, threshold: float = 0.5):
        """
        ä½¿ç”¨åµŒå…¥è¿›è¡Œè®°å¿†æ€»ç»“æŸ¥è¯¢
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        :param query: æŸ¥è¯¢å†…å®¹
        :param top_k: è¿”å›æœ€ç›¸ä¼¼çš„è®°å¿†æ¡æ•°
        :param threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œä½äºæ­¤é˜ˆå€¼çš„ç»“æœå°†è¢«å¿½ç•¥
        :return: æœ€ç›¸ä¼¼çš„è®°å¿†æ€»ç»“æ¡ç›®
        """
        user_memory = self.memory_data.get(token_name, {'memory_summary': [], 'summary_embeddings': []})
        if not user_memory['summary_embeddings']:
            return []

        # ç”ŸæˆæŸ¥è¯¢çš„åµŒå…¥
        query_embedding = self.embedding_model.encode([query])[0]

        # è®¡ç®—æŸ¥è¯¢ä¸è®°å¿†æ€»ç»“çš„ç›¸ä¼¼åº¦
        similarities = [cos_sim(query_embedding, embedding) for embedding in user_memory['summary_embeddings']]

        # è·å–æœ€ç›¸ä¼¼çš„è®°å¿†æ€»ç»“æ¡ç›®ï¼Œè¿‡æ»¤ç›¸ä¼¼åº¦ä½äºé˜ˆå€¼çš„ç»“æœ
        filtered_indices = [i for i, sim in enumerate(similarities) if sim >= threshold]
        top_indices = sorted(filtered_indices, key=lambda i: similarities[i], reverse=True)[:top_k]
        similar_summary = [user_memory['memory_summary'][i] for i in top_indices]

        return similar_summary
    def save_memory(self):
        """
        å°†è®°å¿†ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ï¼Œæ¯ä¸ªæ–‡ä»¶ä»¥token_nameä½œä¸ºæ–‡ä»¶å
        """
        try:
            for token_name, user_data in self.memory_data.items():
                memory_data_serializable = {
                    'memory': list(user_data['memory']),
                    'total_length': user_data['total_length'],
                    'memory_summary': user_data['memory_summary'],
                    'summary_embeddings': [embedding.tolist() for embedding in user_data['summary_embeddings']],
                    'embeddings': [embedding.tolist() for embedding in user_data['embeddings']]
                }

                file_path = os.path.join(self.memory_dir, f"{token_name}.json")
                with open(file_path, 'w+', encoding='utf-8') as file:
                    json.dump(memory_data_serializable, file, ensure_ascii=False, indent=4)
                logger.info(f"è®°å¿†å·²ä¿å­˜è‡³ {file_path}")

        except Exception as e:
            logger.warning(f"ä¿å­˜è®°å¿†æ—¶å‡ºé”™: {e}")

    def load_memory(self):
        """
        ä»æœ¬åœ°æ–‡ä»¶åŠ è½½è®°å¿†æ•°æ®
        """
        try:
            self.memory_data = {}

            for file_name in os.listdir(self.memory_dir):
                if file_name.endswith('.json'):
                    token_name = file_name[:-5]  # å»æ‰ .json åç¼€
                    file_path = os.path.join(self.memory_dir, file_name)

                    with open(file_path, 'r', encoding='utf-8') as file:
                        try:
                            memory_data = json.load(file)
                        except Exception as e:
                            logger.warning(f"åŠ è½½è®°å¿†{file_path}æ—¶å‡ºé”™: {e}")                         
                            continue

                        self.memory_data[token_name] = {
                            'memory': deque(memory_data['memory']),
                            'total_length': memory_data['total_length'],
                            'memory_summary': memory_data['memory_summary'],
                            'summary_embeddings': [np.array(embedding) for embedding in memory_data['summary_embeddings']],
                            'embeddings': deque([np.array(embedding) for embedding in memory_data['embeddings']])
                        }
                    logger.info(f"è®°å¿†å·²ä» {file_path} åŠ è½½")

        except Exception as e:
            logger.warning(f"åŠ è½½è®°å¿†æ—¶å‡ºé”™: {e}")



class Plugin(PluginBase):
    name = "MemoryPlugin"
    def __init__(self, plugin_manager, embd, llm, tts, config):
        super().__init__(plugin_manager, embd, llm, tts, config)
        config_memory = config.get("memory", {})
        self.llm_memory = MemoryManager(
            llm=llm, 
            embd=embd,
            summary_prompt=config_memory.get("summary_prompt", "ä½ è¿˜ä¿ç•™ç€ä¸€äº›é•¿æœŸçš„è®°å¿†ï¼Œè¿™æœ‰åŠ©äºè®©ä½ çš„å¯¹è¯æ›´åŠ ä¸°å¯Œå’Œè¿è´¯ï¼š"),
            max_memory_length=config_memory.get("max_memory_length", 10000),
            max_summary_length=config_memory.get("max_summary_length", 2000),
            summary_length=config_memory.get("summary_length", 1000),
            memory_dir=config_memory.get("memory_dir", "memory_data"),
        )
        plugin_manager.register_event(PluginEvent.CHAT_START, self.on_chat_start)
        plugin_manager.register_event(PluginEvent.DISCONNECT, self.on_disconnect)

    def on_chat_start(self, token_id:str, query:str, chat_history:ChatHistory)->PluginResult:
        new_query = self.llm_memory.handle_user_scene(token_id, query)

        result = PluginResult(success=True)
        if new_query:
            result.add_modify("query", new_query, query)       

        # add summary to chat history
        summary = self.llm_memory.get_memory_summary(token_id)
        if summary is None or summary == "":
            return result

        old_system_prompt = chat_history.get_system_prompt()

        prompt_start = "\n\nä½ è¿˜ä¿ç•™ç€ä¸€äº›é•¿æœŸçš„è®°å¿†ï¼Œè¿™æœ‰åŠ©äºè®©ä½ çš„å¯¹è¯æ›´åŠ ä¸°å¯Œå’Œè¿è´¯:"
        old_system_prompt = old_system_prompt.split(prompt_start)[0]
        new_system_prompt = f"{old_system_prompt}{prompt_start}\n<summary>{summary}</summary>"

        chat_history.set_system_prompt(new_system_prompt)
        
        result.add_modify("chat_history", chat_history)

        return result

    
    async def on_disconnect(self,token_id, chat_history:ChatHistory)->None:
        await self.llm_memory.add_chat_paragraph(token_id,chat_history.get_chat_history_without_system())


if __name__ == '__main__':
    from sentence_transformers import SentenceTransformer
    # ç¤ºä¾‹ä½¿ç”¨
    embedding_model = SentenceTransformer('jinaai/jina-embeddings-v2-base-zh', trust_remote_code=True, device="cpu")
    memory_manager = MemoryManager(llm=None, embd=embedding_model, max_memory_length=100)

    # æ¨¡æ‹Ÿä¸¤æ®µå¯¹è¯
    chat_paragraph1 = [
        {"role": "user", "content": "å¹åˆ°äº†ä½ çš„å‘ã€‚ğŸ˜”"},
        {"role": "assistant", "content": "å‘ä¸è½»æ‹‚ï¼Œç‹¬æ€œæ­¤é™…ï¼Œæ¢¦æ–­è°å®¶ï¼ŸğŸ˜”"}
    ]

    chat_paragraph2 = [
        {"role": "user", "content": "ä»Šå¤©å¤©æ°”ã€‚ğŸ˜”"},
        {"role": "assistant", "content": "æ™´å¤©ï¼ŸğŸ˜”"}
    ]

    # æ·»åŠ ç¬¬ä¸€æ®µèŠå¤©
    asyncio.run(memory_manager.add_chat_paragraph("user1", chat_paragraph1))

    # æ·»åŠ ç¬¬äºŒæ®µèŠå¤©
    asyncio.run(memory_manager.add_chat_paragraph("user1", chat_paragraph2))

    # ä½¿ç”¨åµŒå…¥è¿›è¡Œè®°å¿†æŸ¥è¯¢
    query = "ä»Šå¤©å¤©æ°”?"
    similar_memory = memory_manager.search_memory("user1", query, threshold=0.5)
    print("æœ€ç›¸ä¼¼çš„è®°å¿†å†…å®¹ï¼š", [msg['content'] for msg in similar_memory])

    # ä½¿ç”¨åµŒå…¥è¿›è¡Œè®°å¿†æ€»ç»“æŸ¥è¯¢
    similar_summary = memory_manager.search_memory_summary("user1", query, threshold=0.5)
    print("æœ€ç›¸ä¼¼çš„è®°å¿†æ€»ç»“ï¼š", similar_summary)
