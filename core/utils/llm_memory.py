import hashlib
import threading
import json
import os
from collections import deque
import uuid

from numpy.linalg import norm
import asyncio
from concurrent.futures import ThreadPoolExecutor
import numpy as np
from datetime import datetime
import logging

logger = logging.getLogger(__name__)
# Cosine similarity function
cos_sim = lambda a, b: (a @ b.T) / (norm(a) * norm(b))


import numpy as np

class IntentRecognizer:
    intent_embeddings_cache = {}
    cache_lock = threading.Lock()
    def __init__(self, embedding_model):
        self.embedding_model = embedding_model
        # å­˜å‚¨æ³¨å†Œçš„æ„å›¾å’Œç›¸ä¼¼åº¦é˜ˆå€¼ä»¥åŠå¯¹åº”çš„å›è°ƒå‡½æ•°
        self.intent_callbacks = []
        
    def register_intent(self, intent_phrases, callback_function, similarity_threshold=0.7):
        """
        æ³¨å†Œä¸€ä¸ªæ„å›¾
        :param intent_phrases: æ„å›¾ç›¸å…³çš„çŸ­è¯­åˆ—è¡¨
        :param callback_function: å¯¹åº”çš„å›è°ƒå‡½æ•°
        :param similarity_threshold: æ„å›¾ä¸æŸ¥è¯¢çš„ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œé»˜è®¤ä¸º0.7
        """
        with self.cache_lock:
            for phrase in intent_phrases:
                # å¦‚æœè¯¥çŸ­è¯­çš„åµŒå…¥å·²ç»ç¼“å­˜ï¼Œåˆ™ç›´æ¥ä½¿ç”¨ç¼“å­˜
                if phrase not in IntentRecognizer.intent_embeddings_cache:
                    # è®¡ç®—åµŒå…¥å¹¶ç¼“å­˜
                    intent_embedding = self.embedding_model.encode([phrase])[0]
                    IntentRecognizer.intent_embeddings_cache[phrase] = intent_embedding
                else:
                    # ä½¿ç”¨ç¼“å­˜çš„åµŒå…¥
                    intent_embedding = IntentRecognizer.intent_embeddings_cache[phrase]

                # å­˜å‚¨æ¯ä¸ªæ„å›¾çŸ­è¯­åŠå…¶å¯¹åº”çš„å›è°ƒå‡½æ•°å’Œç›¸ä¼¼åº¦é˜ˆå€¼
                self.intent_callbacks.append({
                    "phrase": phrase,
                    "embedding": intent_embedding,
                    "callback": callback_function,
                    "threshold": similarity_threshold
                })

    def handle_query(self, query: str, *args, **kwargs):
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢å¹¶è¿›è¡Œæ„å›¾è¯†åˆ«ï¼Œè°ƒç”¨åŒ¹é…çš„å›è°ƒå‡½æ•°
        :param query: ç”¨æˆ·æŸ¥è¯¢
        :param args: ä»»æ„ä½ç½®å‚æ•°ä¼ é€’ç»™å›è°ƒå‡½æ•°
        :param kwargs: ä»»æ„å…³é”®å­—å‚æ•°ä¼ é€’ç»™å›è°ƒå‡½æ•°
        :return: å›è°ƒå‡½æ•°çš„è¿”å›å€¼
        """
        query = query.strip()
        # è®¡ç®—ç”¨æˆ·æŸ¥è¯¢çš„åµŒå…¥è¡¨ç¤º
        query_embedding = self.embedding_model.encode([query])[0]
        
        best_match = None
        highest_similarity = -1
        matched_callback = None

        # æ¯”è¾ƒæŸ¥è¯¢ä¸æ³¨å†Œçš„æ„å›¾çŸ­è¯­çš„ç›¸ä¼¼åº¦
        for intent in self.intent_callbacks:
            similarity = np.dot(query_embedding, intent["embedding"]) / (np.linalg.norm(query_embedding) * np.linalg.norm(intent["embedding"]))
            if similarity > highest_similarity and similarity >= intent["threshold"]:
                highest_similarity = similarity
                best_match = intent["phrase"]
                matched_callback = intent["callback"]

        if best_match and matched_callback:
            # è°ƒç”¨ä¸åŒ¹é…æ„å›¾å¯¹åº”çš„å›è°ƒå‡½æ•°ï¼Œä¼ é€’ä½ç½®å‚æ•°å’Œå…³é”®å­—å‚æ•°
            logger.info(f"{query}\tæ„å›¾è¯†åˆ«ç»“æœï¼š{best_match}\tfunc:{matched_callback}\t (ç›¸ä¼¼åº¦: {highest_similarity:.2f})")
            return matched_callback(query,*args, **kwargs)
        logger.info(f"{query}\tæœªè¯†åˆ«åˆ°æ„å›¾")
        return None






class MemoryManager:
    _instance = None
    _lock = threading.Lock()

    def __new__(cls, *args, **kwargs):
        with cls._lock:
            if cls._instance is None:
                cls._instance = super(MemoryManager, cls).__new__(cls)  
        return cls._instance

    def __init__(
            self,
            llm,
            embd,
            summary_prompt: str = "è¯·æ€»ç»“ä¸‹é¢çš„èŠå¤©å†…å®¹,å¿…é¡»åœ¨{content_len}å­—æ•°ä»¥å†…ï¼Œå¿…é¡»åŒ…å«èŠå¤©çš„å®Œæ•´ç»†èŠ‚:\n\n{content}",
            max_memory_length: int = 1000,
            summary_length: int = 1000,
            max_summary_length: int = 2000,

            memory_dir='memory_data'
        ):
        """
        åˆå§‹åŒ–è®°å¿†ç®¡ç†ç±»
        :param embedding_model: ç”¨äºç”Ÿæˆæ–‡æœ¬åµŒå…¥çš„æ¨¡å‹
        :param max_memory_length: æœ€å¤§è®°å¿†æ€»å­—ç¬¦é•¿åº¦
        :param summary_length: æ¯æ¬¡ç”Ÿæˆçš„æ€»ç»“çš„é•¿åº¦
        :param memory_file: ä¿å­˜è®°å¿†æ•°æ®çš„æ–‡ä»¶è·¯å¾„
        """
        logger.info(f"åˆå§‹åŒ–è®°å¿†ç®¡ç†å™¨ max_memory_length:{max_memory_length} summary_length:{summary_length} max_summary_length:{max_summary_length}")
        self.max_memory_length = max_memory_length
        self.summary_length = summary_length
        self.max_summary_length = max_summary_length

        self.memory_data = {}  # ç”¨å­—å…¸ç®¡ç†æ¯ä¸ªç”¨æˆ·çš„è®°å¿†
        self.lock = threading.Lock()  # é”å¯¹è±¡ï¼Œç”¨äºçº¿ç¨‹åŒæ­¥
        self.summary_prompt = summary_prompt
        self.llm = llm
        self.embedding_model = embd  # ç”¨äºç”Ÿæˆæ–‡æœ¬çš„åµŒå…¥

        self.memory_dir = memory_dir
        if not os.path.exists(self.memory_dir):
            os.makedirs(self.memory_dir,exist_ok=True)  # åˆ›å»ºç›®å½•
        
        # ç¡®ä¿ç›®å½•å…·æœ‰è¯»å†™æƒé™
        if not os.access(self.memory_dir, os.W_OK):
            try:
                os.chmod(self.memory_dir, 0o700)  # è®¾ç½®è¯»å†™æƒé™
                logger.info(f"å·²ä¸ºç›®å½• {self.memory_dir} è®¾ç½®è¯»å†™æƒé™")
            except Exception as e:
                logger.warning(f"æ— æ³•ä¿®æ”¹ {self.memory_dir} çš„æƒé™: {e}")
                raise PermissionError(f"æ²¡æœ‰è¶³å¤Ÿæƒé™è®¿é—®ç›®å½•: {self.memory_dir}")
        # åŠ è½½å·²æœ‰è®°å¿†æˆ–åˆå§‹åŒ–æ–°çš„è®°å¿†
        self.load_memory()
        
        # ThreadPoolExecutor for async tasks
        self.executor = ThreadPoolExecutor()


        self.intent_recognizer = IntentRecognizer(self.embedding_model)
        self.intent_recognizer.register_intent(
            ["å›å¿†å¯¹è¯", "å›å¿†ä¸Šæ¬¡è®²çš„", "è¯·å›å¿†","æœ‰ä»€ä¹ˆè®°å¿†","åˆšæ‰è®²äº†ä»€ä¹ˆ","ä¸Šæ¬¡è®²äº†ä»€ä¹ˆ"], 
            self._recall_last_conversation, 
            similarity_threshold=0.7
        )
        self.intent_recognizer.register_intent(
            ["åˆ é™¤æˆ‘çš„è®°å¿†","åˆ é™¤æ‰€æœ‰è®°å¿†"], 
            self._del_all, 
            similarity_threshold=0.9
        )       
    
    def _recall_last_conversation(self,query: str, token_name: str)->str:
        """
        å›å¿†ä¸Šæ¬¡çš„å¯¹è¯
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        :param query: ç”¨æˆ·æŸ¥è¯¢
        :return: ä¸Šæ¬¡çš„å¯¹è¯å†…å®¹
        """
        user_memory = self.search_memory(token_name, query, top_k=5)
        

        if len(user_memory) == 0:
            
            user_memory = self.memory_data.get(token_name, {'memory':[]})
            
            user_memory = list(user_memory['memory'])
            user_memory = user_memory[-10:]        

            

        output = "\n".join([msg['content'] for msg in user_memory])

        
        return f"{query}\n\næˆ‘ä»¬ä¸Šæ¬¡èŠåˆ°äº†:\n\n{output}"

    def _generate_summary(self, chat_paragraph: list):
        """
        ç”ŸæˆèŠå¤©å†…å®¹çš„æ€»ç»“ï¼ˆå¯ä»¥æ ¹æ®å…·ä½“è¦æ±‚å®šåˆ¶æ€»ç»“é€»è¾‘ï¼‰
        :param chat_content: èŠå¤©å†…å®¹
        :return: æ€»ç»“çš„å­—ç¬¦ä¸²
        """
        if self.llm is None:
            return "".join([msg['content'] for msg in chat_paragraph])[:self.summary_length]
        
        response_message = []
        try:            
            llm_responses = self.llm.response(
                str(uuid.uuid4()), 
                [
                    {
                        "role": "user", 
                        "content": self.summary_prompt.format(content=json.dumps(chat_paragraph),content_len=self.summary_length)
                    }
                ]
            )
        except Exception as e:
            logger.warning(f"LLM å¤„ç†å‡ºé”™ {query}: {e}")
            return None

        for content in llm_responses:
            response_message.append(content)
        return "".join(response_message)

    def _forget_old_memory(self, token_name: str):
        """
        è¶…è¿‡æœ€å¤§è®°å¿†æ€»é•¿åº¦æ—¶ï¼Œåˆ é™¤ä¸é‡è¦çš„è®°å¿†
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        """
        user_memory = self.memory_data.get(token_name, {'memory': deque(), 'total_length': 0})

        while user_memory['total_length'] > self.max_memory_length and user_memory['memory']:
            # åˆ é™¤æœ€æ—§çš„èŠå¤©å†…å®¹å’Œå¯¹åº”çš„åµŒå…¥
            oldest_message = user_memory['memory'].popleft()
            oldest_embedding = user_memory['embeddings'].popleft()  # Remove corresponding embedding
            user_memory['total_length'] -= len(oldest_message['content'])



    def _update_summary(self, token_name: str, chat_paragraph: list[dict]):
        """
        æ›´æ–°è®°å¿†æ€»ç»“ï¼Œåˆå¹¶æ¯ä¸ªèŠå¤©æ®µè½çš„å†…å®¹å¹¶ç”Ÿæˆæ‘˜è¦
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        """      
        
        if len(chat_paragraph) == 0:
            return 
        
        summary = self._generate_summary(chat_paragraph)

        if summary is None or len(summary.strip()) == 0:
            return
        
        self.memory_data[token_name].setdefault('memory_summary', []).append(summary)

        # ç”Ÿæˆå¹¶ä¿å­˜æ‘˜è¦çš„åµŒå…¥
        summary_embedding = self.embedding_model.encode([summary])[0]
        self.memory_data[token_name].setdefault('summary_embeddings', []).append(summary_embedding)

    def _combine_summary(self, token_name: str):
        """
        å°†æ‰€æœ‰çš„è®°å¿†æ€»ç»“åˆå¹¶ä¸ºä¸€ä¸ª
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        """
        
        user_memory = self.memory_data.get(token_name, {'memory_summary': []})

        # å¦‚æœæ²¡æœ‰è¶…è¿‡æœ€å¤§æ€»ç»“é•¿åº¦ï¼Œç›´æ¥è¿”å›
        old_summary = "".join(user_memory['memory_summary'])
        if len(user_memory) == 0 or len(old_summary) < self.max_memory_length:
            logger.debug("ä¸éœ€è¦åˆå¹¶,æ€»ç»“é•¿åº¦ï¼š", len(old_summary))
            return
        logger.debug("åˆå¹¶å‰çš„æ€»ç»“é•¿åº¦ï¼š", len(old_summary))
        summary = self._generate_summary(user_memory['memory_summary'])
        logger.debug("åˆå¹¶åçš„æ€»ç»“é•¿åº¦ï¼š", len(summary))
        self.memory_data[token_name]['memory_summary'] = [summary]

        # ç”Ÿæˆå¹¶ä¿å­˜æ‘˜è¦çš„åµŒå…¥
        summary_embedding = self.embedding_model.encode([summary])[0]
        self.memory_data[token_name]['summary_embeddings'] = [summary_embedding]

    def _del_all(self, query:str, token_name: str)->str:
        """
        åˆ é™¤æ‰€æœ‰è®°å¿†
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        """
        self.memory_data[token_name] = {'memory': deque(), 'total_length': 0, 'memory_summary': [], 'summary_embeddings': [], 'embeddings': deque()}
        self.save_memory()
        return f"ä½ å¿…é¡»{query}\n\nä½ å¿…é¡»å›ç­”åŒæ„åˆ é™¤æ‰€æœ‰è®°å¿†"

    async def add_chat_paragraph(self, token_name: str, chat_paragraph: list[dict]):
        """
        æ·»åŠ ä¸€æ®µèŠå¤©å†…å®¹åˆ°è®°å¿†ä¸­
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        :param chat_paragraph: èŠå¤©æ®µè½ï¼ŒåŒ…å«å¤šæ¡èŠå¤©è®°å½•
        """
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(self.executor, self._add_chat_paragraph, token_name, chat_paragraph)

    def _add_chat_paragraph(self, token_name: str, chat_paragraph: list[dict]):
        with self.lock:  # ä½¿ç”¨é”ä¿è¯çº¿ç¨‹å®‰å…¨
            if token_name not in self.memory_data:
                self.memory_data[token_name] = {'memory': deque(), 'total_length': 0, 'memory_summary': [], 'summary_embeddings': [], 'embeddings': deque()}

            user_memory = self.memory_data[token_name]
            new_embeddings = []

            for message in chat_paragraph:
                role = message['role']
                content = message['content']

                chat_hash = hashlib.md5(content.encode()).hexdigest()

                user_memory['memory'].append({"role": role, "content": content, "hash": chat_hash, "datatime": "{:%Y-%m-%d %H:%M:%S}".format(datetime.now())})
                user_memory['total_length'] += len(content)

                # ç”ŸæˆåµŒå…¥
                embedding = self.embedding_model.encode([content])[0]  # ä½¿ç”¨åµŒå…¥æ¨¡å‹ç”ŸæˆåµŒå…¥
                user_memory['embeddings'].append(embedding)

            # æ›´æ–°è®°å¿†æ€»ç»“
            self._update_summary(token_name, chat_paragraph)

            # å¦‚æœè®°å¿†è¶…å‡ºäº†é™åˆ¶ï¼Œåˆ é™¤ä¸é‡è¦çš„å†…å®¹
            self._forget_old_memory(token_name)

            # åˆå¹¶å‹ç¼©è®°å¿†æ€»ç»“
            self._combine_summary(token_name)

            # ä¿å­˜è®°å¿†åˆ°æ–‡ä»¶
            self.save_memory()

    def handle_user_scene(self,token_name:str, query: str) -> str:
        """
        è§£æç”¨æˆ·æŸ¥è¯¢
        :param query: ç”¨æˆ·æŸ¥è¯¢
        :return: è§£æåçš„æŸ¥è¯¢
        """
        query = query.strip()
        if len(query) == 0:
            return query
        
        result = self.intent_recognizer.handle_query(query, token_name)
        if result is None:
            return query

        return result
    

    def get_memory_summary(self, token_name: str) -> str:
        """
        è·å–å½“å‰ç”¨æˆ·çš„è®°å¿†æ€»ç»“
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        :return: å½“å‰çš„æ€»ç»“
        """
        user_memory = self.memory_data.get(token_name, {'memory_summary': []})
        return "\n\n".join(user_memory['memory_summary'])

    def get_full_memory(self, token_name: str) -> list[str]:
        """
        è·å–å½“å‰ç”¨æˆ·çš„å®Œæ•´è®°å¿†å†…å®¹
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        :return: å½“å‰çš„æ‰€æœ‰è®°å¿†å†…å®¹
        """
        user_memory = self.memory_data.get(token_name, {'memory': []})
        return [msg['content'] for msg in user_memory['memory']]

    def search_memory(self, token_name: str, query: str, top_k: int = 5, threshold: float = 0.5):
        """
        ä½¿ç”¨åµŒå…¥è¿›è¡Œè®°å¿†æŸ¥è¯¢
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        :param query: æŸ¥è¯¢å†…å®¹
        :param top_k: è¿”å›æœ€ç›¸ä¼¼çš„è®°å¿†æ¡æ•°
        :param threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œä½äºæ­¤é˜ˆå€¼çš„ç»“æœå°†è¢«å¿½ç•¥
        :return: æœ€ç›¸ä¼¼çš„è®°å¿†æ¡ç›®
        """
        user_memory = self.memory_data.get(token_name, {'embeddings': []})
        if not user_memory['embeddings']:
            return []

        # ç”ŸæˆæŸ¥è¯¢çš„åµŒå…¥
        query_embedding = self.embedding_model.encode([query])[0]

        # è®¡ç®—æŸ¥è¯¢ä¸è®°å¿†ä¸­æ¯æ¡æ¶ˆæ¯çš„ç›¸ä¼¼åº¦
        similarities = [cos_sim(query_embedding, embedding) for embedding in user_memory['embeddings']]

        # è·å–æœ€ç›¸ä¼¼çš„è®°å¿†æ¡ç›®ï¼Œè¿‡æ»¤ç›¸ä¼¼åº¦ä½äºé˜ˆå€¼çš„ç»“æœ
        filtered_indices = [i for i, sim in enumerate(similarities) if sim >= threshold]
        top_indices = sorted(filtered_indices, key=lambda i: similarities[i], reverse=True)[:top_k]
        similar_memory = [user_memory['memory'][i] for i in top_indices]

        return similar_memory

    def search_memory_summary(self, token_name: str, query: str, top_k: int = 5, threshold: float = 0.5):
        """
        ä½¿ç”¨åµŒå…¥è¿›è¡Œè®°å¿†æ€»ç»“æŸ¥è¯¢
        :param token_name: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ç¬¦
        :param query: æŸ¥è¯¢å†…å®¹
        :param top_k: è¿”å›æœ€ç›¸ä¼¼çš„è®°å¿†æ¡æ•°
        :param threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œä½äºæ­¤é˜ˆå€¼çš„ç»“æœå°†è¢«å¿½ç•¥
        :return: æœ€ç›¸ä¼¼çš„è®°å¿†æ€»ç»“æ¡ç›®
        """
        user_memory = self.memory_data.get(token_name, {'memory_summary': [], 'summary_embeddings': []})
        if not user_memory['summary_embeddings']:
            return []

        # ç”ŸæˆæŸ¥è¯¢çš„åµŒå…¥
        query_embedding = self.embedding_model.encode([query])[0]

        # è®¡ç®—æŸ¥è¯¢ä¸è®°å¿†æ€»ç»“çš„ç›¸ä¼¼åº¦
        similarities = [cos_sim(query_embedding, embedding) for embedding in user_memory['summary_embeddings']]

        # è·å–æœ€ç›¸ä¼¼çš„è®°å¿†æ€»ç»“æ¡ç›®ï¼Œè¿‡æ»¤ç›¸ä¼¼åº¦ä½äºé˜ˆå€¼çš„ç»“æœ
        filtered_indices = [i for i, sim in enumerate(similarities) if sim >= threshold]
        top_indices = sorted(filtered_indices, key=lambda i: similarities[i], reverse=True)[:top_k]
        similar_summary = [user_memory['memory_summary'][i] for i in top_indices]

        return similar_summary
    def save_memory(self):
        """
        å°†è®°å¿†ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ï¼Œæ¯ä¸ªæ–‡ä»¶ä»¥token_nameä½œä¸ºæ–‡ä»¶å
        """
        try:
            for token_name, user_data in self.memory_data.items():
                memory_data_serializable = {
                    'memory': list(user_data['memory']),
                    'total_length': user_data['total_length'],
                    'memory_summary': user_data['memory_summary'],
                    'summary_embeddings': [embedding.tolist() for embedding in user_data['summary_embeddings']],
                    'embeddings': [embedding.tolist() for embedding in user_data['embeddings']]
                }

                file_path = os.path.join(self.memory_dir, f"{token_name}.json")
                with open(file_path, 'w', encoding='utf-8') as file:
                    json.dump(memory_data_serializable, file, ensure_ascii=False, indent=4)
                logger.info(f"è®°å¿†å·²ä¿å­˜è‡³ {file_path}")

        except Exception as e:
            logger.warning(f"ä¿å­˜è®°å¿†æ—¶å‡ºé”™: {e}")

    def load_memory(self):
        """
        ä»æœ¬åœ°æ–‡ä»¶åŠ è½½è®°å¿†æ•°æ®
        """
        try:
            self.memory_data = {}

            for file_name in os.listdir(self.memory_dir):
                if file_name.endswith('.json'):
                    token_name = file_name[:-5]  # å»æ‰ .json åç¼€
                    file_path = os.path.join(self.memory_dir, file_name)

                    with open(file_path, 'r', encoding='utf-8') as file:
                        try:
                            memory_data = json.load(file)
                        except Exception as e:
                            logger.warning(f"åŠ è½½è®°å¿†{file_path}æ—¶å‡ºé”™: {e}")                         
                            continue

                        self.memory_data[token_name] = {
                            'memory': deque(memory_data['memory']),
                            'total_length': memory_data['total_length'],
                            'memory_summary': memory_data['memory_summary'],
                            'summary_embeddings': [np.array(embedding) for embedding in memory_data['summary_embeddings']],
                            'embeddings': deque([np.array(embedding) for embedding in memory_data['embeddings']])
                        }
                    logger.info(f"è®°å¿†å·²ä» {file_path} åŠ è½½")

        except Exception as e:
            logger.warning(f"åŠ è½½è®°å¿†æ—¶å‡ºé”™: {e}")
            

if __name__ == '__main__':
    from sentence_transformers import SentenceTransformer
    # ç¤ºä¾‹ä½¿ç”¨
    embedding_model = SentenceTransformer('jinaai/jina-embeddings-v2-base-zh', trust_remote_code=True, device="cpu")
    memory_manager = MemoryManager(llm=None, embedding_model=embedding_model, max_memory_length=100)

    # æ¨¡æ‹Ÿä¸¤æ®µå¯¹è¯
    chat_paragraph1 = [
        {"role": "user", "content": "å¹åˆ°äº†ä½ çš„å‘ã€‚ğŸ˜”"},
        {"role": "assistant", "content": "å‘ä¸è½»æ‹‚ï¼Œç‹¬æ€œæ­¤é™…ï¼Œæ¢¦æ–­è°å®¶ï¼ŸğŸ˜”"}
    ]

    chat_paragraph2 = [
        {"role": "user", "content": "ä»Šå¤©å¤©æ°”ã€‚ğŸ˜”"},
        {"role": "assistant", "content": "æ™´å¤©ï¼ŸğŸ˜”"}
    ]

    # æ·»åŠ ç¬¬ä¸€æ®µèŠå¤©
    asyncio.run(memory_manager.add_chat_paragraph("user1", chat_paragraph1))

    # æ·»åŠ ç¬¬äºŒæ®µèŠå¤©
    asyncio.run(memory_manager.add_chat_paragraph("user1", chat_paragraph2))

    # ä½¿ç”¨åµŒå…¥è¿›è¡Œè®°å¿†æŸ¥è¯¢
    query = "ä»Šå¤©å¤©æ°”?"
    similar_memory = memory_manager.search_memory("user1", query, threshold=0.5)
    print("æœ€ç›¸ä¼¼çš„è®°å¿†å†…å®¹ï¼š", [msg['content'] for msg in similar_memory])

    # ä½¿ç”¨åµŒå…¥è¿›è¡Œè®°å¿†æ€»ç»“æŸ¥è¯¢
    similar_summary = memory_manager.search_memory_summary("user1", query, threshold=0.5)
    print("æœ€ç›¸ä¼¼çš„è®°å¿†æ€»ç»“ï¼š", similar_summary)
